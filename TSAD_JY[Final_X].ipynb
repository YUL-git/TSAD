{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSAD_JY[Final_X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import ArgumentParser\n",
    "\n",
    "parser = ArgumentParser(description=\"Univariate with Exogenous TSAD\")\n",
    "\n",
    "parser.add_argument('--train_path', default='data/raw_data/train/Training_Data.csv', type=str, help='path to the data')\n",
    "parser.add_argument('--test1_path', default='data/raw_data/test/WeldingTest_01_OK.csv', type=str, help='path to the data')\n",
    "parser.add_argument('--test2_path', default='data/raw_data/test/WeldingTest_02_OK.csv', type=str, help='path to the data')\n",
    "parser.add_argument('--test3_path', default='data/raw_data/test/WeldingTest_03_NG.csv', type=str, help='path to the data')\n",
    "parser.add_argument('--test4_path', default='data/raw_data/test/WeldingTest_04_NG.csv', type=str, help='path to the data')\n",
    "parser.add_argument('--label3_path', default='data/preprocessed/test/WeldingTest_03_NG_Label.csv', type=str, help='path to the data')\n",
    "\n",
    "parser.add_argument('--horizon', default=10, type=int, help='forecast horizon')\n",
    "parser.add_argument('--input_size', default=20, type=int, help='input size')\n",
    "parser.add_argument('--threshold', default=4.0, type=float, help='threshold')\n",
    "\n",
    "args = parser.parse_args('')\n",
    "\n",
    "CFG = {\n",
    "    \"train\"  : args.train_path,\n",
    "    \"test1\"  : args.test1_path,\n",
    "    \"test2\"  : args.test2_path,\n",
    "    \"test3\"  : args.test3_path,\n",
    "    \"test4\"  : args.test4_path,\n",
    "    \"label3\" : args.label3_path,\n",
    "    \n",
    "    \"horizon\"     : args.horizon,\n",
    "    \"input_size\"  : args.input_size,\n",
    "    \"threshold\"   : args.threshold\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'  ## MULTI GPU 사용시 고정\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.getcwd()\n",
    "path = os.path.join(root, CFG['train']) # path 수정\n",
    "data = pd.read_csv(path)\n",
    "data = data.rename(columns=lambda col_name: col_name.strip())\n",
    "\n",
    "data.drop(columns=['SetFrequency', 'SetDuty'], inplace=True)\n",
    "\n",
    "cols = [data.columns[3]]\n",
    "df_rp = data[cols]\n",
    "for i in range(len(data)):\n",
    "    if data[data.columns[3]][i] < 1300.0:\n",
    "        df_rp[data.columns[3]][i] = df_rp[data.columns[3]][i] +930.5\n",
    "\n",
    "data.loc[:, 'RealPower'] = df_rp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_columns = data.columns.tolist()\n",
    "# use_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data) * 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:10800]\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = os.path.join(root, CFG['test1']) # path 수정\n",
    "test1 = pd.read_csv(path)\n",
    "test1 = test1.rename(columns=lambda col_name: col_name.strip())\n",
    "test1 = test1[use_columns]\n",
    "\n",
    "cols = [test1.columns[3]]\n",
    "\n",
    "df_test1 = test1[cols]\n",
    "for i in range(len(test1)):\n",
    "    if test1[test1.columns[3]][i] <1300.0:\n",
    "        df_test1[test1.columns[3]][i] = df_test1[test1.columns[3]][i] +930.5\n",
    "\n",
    "test1.loc[:, 'RealPower'] = df_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = os.path.join(root, CFG['test2']) # path 수정\n",
    "test2 = pd.read_csv(path)\n",
    "test2 = test2.rename(columns=lambda col_name: col_name.strip())\n",
    "test2 = test2[use_columns]\n",
    "\n",
    "cols = [test2.columns[3]]\n",
    "\n",
    "df_test2 = test2[cols]\n",
    "for i in range(len(test2)):\n",
    "    if test2[test2.columns[3]][i] <1300.0:\n",
    "        df_test2[test2.columns[3]][i] = df_test2[test2.columns[3]][i] +930.5\n",
    "\n",
    "test2.loc[:, 'RealPower'] = df_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = os.path.join(root, CFG['test3']) # path 수정\n",
    "test3 = pd.read_csv(path)\n",
    "test3 = test3.rename(columns=lambda col_name: col_name.strip())\n",
    "test3 = test3[use_columns]\n",
    "\n",
    "cols = [test3.columns[3]]\n",
    "\n",
    "df_test3 = test3[cols]\n",
    "for i in range(len(test3)):\n",
    "    if test3[test3.columns[3]][i] <1300.0:\n",
    "        df_test3[test3.columns[3]][i] = df_test3[test3.columns[3]][i] +930.5\n",
    "\n",
    "test3.loc[:, 'RealPower'] = df_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path  = os.path.join(root, CFG['test4']) # path 수정\n",
    "test4 = pd.read_csv(path)\n",
    "test4 = test4.rename(columns=lambda col_name: col_name.strip())\n",
    "test4 = test4[use_columns]\n",
    "\n",
    "cols = [test4.columns[3]]\n",
    "\n",
    "df_test4 = test4[cols]\n",
    "for i in range(len(test4)):\n",
    "    if test4[test4.columns[3]][i] <1300.0:\n",
    "        df_test4[test4.columns[3]][i] = df_test4[test4.columns[3]][i] +930.5\n",
    "\n",
    "test4.loc[:, 'RealPower'] = df_test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_id_cols = ['PageNo', 'Speed', 'Length', 'RealPower', 'SetPower', 'GateOnTime']\n",
    "\n",
    "data['ds'] = pd.to_datetime(data.index, unit='s')\n",
    "\n",
    "train_data = data.rename(columns={'RealPower': 'y'}).assign(\n",
    "    unique_id='RealPower'\n",
    ")\n",
    "\n",
    "train_data  = train_data[['ds', 'unique_id', 'y'] + [col for col in unique_id_cols if col != 'RealPower']]\n",
    "\n",
    "test1['ds'] = pd.to_datetime(test1.index, unit='s')\n",
    "test_data1  = test1.rename(columns={'RealPower': 'y'}).assign(\n",
    "    unique_id='RealPower'\n",
    ")\n",
    "test_data1  = test_data1[['ds', 'unique_id', 'y'] + [col for col in unique_id_cols if col != 'RealPower']]\n",
    "\n",
    "test2['ds'] = pd.to_datetime(test2.index, unit='s')\n",
    "test_data2  = test2.rename(columns={'RealPower': 'y'}).assign(\n",
    "    unique_id='RealPower'\n",
    ")\n",
    "test_data2  = test_data2[['ds', 'unique_id', 'y'] + [col for col in unique_id_cols if col != 'RealPower']]\n",
    "\n",
    "test3['ds'] = pd.to_datetime(test3.index, unit='s')\n",
    "test_data3  = test3.rename(columns={'RealPower': 'y'}).assign(\n",
    "    unique_id='RealPower'\n",
    ")\n",
    "test_data3  = test_data3[['ds', 'unique_id', 'y'] + [col for col in unique_id_cols if col != 'RealPower']]\n",
    "\n",
    "test4['ds'] = pd.to_datetime(test4.index, unit='s')\n",
    "test_data4  = test4.rename(columns={'RealPower': 'y'}).assign(\n",
    "    unique_id='RealPower'\n",
    ")\n",
    "test_data4  = test_data4[['ds', 'unique_id', 'y'] + [col for col in unique_id_cols if col != 'RealPower']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model.py\n",
    "* 사용 모델: TSMixerx, NHITS, NBEATSx, LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralforecast import NeuralForecast\n",
    "from neuralforecast.models import TSMixerx, NHITS, NBEATSx, LSTM, GRU\n",
    "from neuralforecast.losses.pytorch import MAE, MQLoss, MSE\n",
    "\n",
    "import math\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon    = CFG['horizon']\n",
    "input_size = CFG['input_size']\n",
    "\n",
    "models = [\n",
    "            TSMixerx(\n",
    "                h           = horizon,\n",
    "                input_size  = input_size,\n",
    "                n_series    = 1,            ## exogenous 변수가 없기 때문 (외부 변수)\n",
    "                scaler_type = 'identity',\n",
    "                max_steps   = 500,\n",
    "                loss        = MSE(),\n",
    "                valid_loss  = MSE(),\n",
    "                batch_size  = 128,\n",
    "                random_seed = 42,\n",
    "                val_check_steps = 100,\n",
    "                early_stop_patience_steps = 5,\n",
    "                hist_exog_list = ['PageNo', 'Speed', 'Length', 'SetPower', 'GateOnTime'],\n",
    "                ),\n",
    "\n",
    "            NHITS(\n",
    "                h           = horizon,\n",
    "                input_size  = input_size,\n",
    "                scaler_type = 'identity',\n",
    "                loss        = MSE(),\n",
    "                valid_loss  = MSE(),\n",
    "                batch_size  = 128,\n",
    "                random_seed = 42,\n",
    "                val_check_steps = 5,\n",
    "                hist_exog_list = ['PageNo', 'Speed', 'Length', 'SetPower', 'GateOnTime'],\n",
    "                early_stop_patience_steps = -1,\n",
    "                ),\n",
    "\n",
    "            NBEATSx(\n",
    "                h           = horizon,\n",
    "                input_size  = input_size,\n",
    "                scaler_type = 'identity',\n",
    "                loss        = MSE(),\n",
    "                valid_loss  = MSE(),\n",
    "                batch_size  = 128,\n",
    "                random_seed = 42,\n",
    "                val_check_steps = 5,\n",
    "                hist_exog_list = ['PageNo', 'Speed', 'Length', 'SetPower', 'GateOnTime'],\n",
    "                early_stop_patience_steps = -1,\n",
    "                ),\n",
    "            \n",
    "            LSTM(\n",
    "                h           = horizon,\n",
    "                input_size  = input_size,\n",
    "                scaler_type = 'identity',\n",
    "                loss        = MSE(),\n",
    "                valid_loss  = MSE(),\n",
    "                batch_size  = 128,\n",
    "                random_seed = 42,\n",
    "                val_check_steps = 5,\n",
    "                hist_exog_list = ['PageNo', 'Speed', 'Length', 'SetPower', 'GateOnTime'],\n",
    "                early_stop_patience_steps = -1,\n",
    "                ),\n",
    "            \n",
    "            GRU(\n",
    "                h           = horizon,\n",
    "                input_size  = input_size,\n",
    "                scaler_type = 'identity',\n",
    "                loss        = MSE(),\n",
    "                valid_loss  = MSE(),\n",
    "                batch_size  = 128,\n",
    "                random_seed = 42,\n",
    "                val_check_steps = 5,\n",
    "                hist_exog_list = ['PageNo', 'Speed', 'Length', 'SetPower', 'GateOnTime'],\n",
    "                early_stop_patience_steps = -1,\n",
    "                ),\n",
    "            \n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nf = NeuralForecast(models = models, freq = 's')\n",
    "train_hat_data = nf.cross_validation(\n",
    "                                    df = train_data,\n",
    "                                    val_size  = CFG['horizon'],\n",
    "                                    test_size = CFG['horizon'],\n",
    "                                    n_windows = None,\n",
    "                                    verbose   = False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_hat_data = train_hat_data.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference NG3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 예측을 위해 windowed dataset 생성 (NIXTLA 맞춤)\n",
    "\n",
    "def create_windowed_dataset(data, window_length=input_size, stride=horizon):\n",
    "    \n",
    "    total_windowed_data = []\n",
    "    total_y_true_data   = []\n",
    "\n",
    "    unique_ids = data['unique_id'].unique()\n",
    "    sample_data = data[data['unique_id'] == unique_ids[0]]\n",
    "    \n",
    "    for start in range(0, len(sample_data) - window_length - horizon + 1, stride):\n",
    "        windowed_data = []\n",
    "        y_true_data   = []\n",
    "    \n",
    "        end = start + window_length\n",
    "\n",
    "        for unique_id in unique_ids:\n",
    "            data_id = data[data['unique_id'] == unique_id]\n",
    "            window = data_id.iloc[start:end]\n",
    "            windowed_data.append(window)\n",
    "            \n",
    "            y_true = data_id.iloc[end:end+horizon]\n",
    "            y_true_data.append(y_true)\n",
    "\n",
    "        total_windowed_data.append(pd.concat(windowed_data))\n",
    "        total_y_true_data.append(pd.concat(y_true_data))\n",
    "        \n",
    "    return total_windowed_data, total_y_true_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## windowed dataset 예측\n",
    "\n",
    "def time_series_anomaly_detection(nf, total_windowed_data):\n",
    "    \n",
    "    forecasts = []\n",
    "    \n",
    "    for window in total_windowed_data:\n",
    "\n",
    "        forecast = nf.predict(window, verbose=False)\n",
    "        forecasts.append(forecast)\n",
    "\n",
    "    return forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anomaly_score(merged_df, gt, error_name_list, thres=CFG['threshold']):\n",
    "\n",
    "    total_length = merged_df.shape[0]\n",
    "    gt   = gt[20 : 20 + total_length]\n",
    "    gt   = np.array(gt)\n",
    "    threshold = thres\n",
    "\n",
    "    for model in model_name_list:\n",
    "\n",
    "        final_scores = merged_df[f'{model}_error'].to_numpy()\n",
    "        avg   = np.mean(final_scores)\n",
    "        sigma = np.std(final_scores)\n",
    "\n",
    "        Z_score = (final_scores - avg) / sigma\n",
    "        pred = (np.abs(Z_score) > threshold).astype(int)\n",
    "        pred = np.array(pred)\n",
    "        \n",
    "        accuracy = accuracy_score(gt, pred)\n",
    "        precision, recall, f_score, support = precision_recall_fscore_support(gt, pred,\n",
    "            average='binary')\n",
    "        \n",
    "        print(\n",
    "            \"Accuracy : {:0.4f}, Precision : {:0.4f}, Recall : {:0.4f}, F-score : {:0.4f}\".format(\n",
    "            accuracy, precision,\n",
    "            recall, f_score), f\" --- {model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_windowed_data, total_y_true_data = create_windowed_dataset(test_data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (주의) 출력이 아주 김\n",
    "\n",
    "\n",
    "forecasts = time_series_anomaly_detection(nf, total_windowed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_df = pd.concat(forecasts)\n",
    "forecasts_df = forecasts_df.sort_values(by=[\"unique_id\", \"ds\"])\n",
    "forecasts_df['unique_id'] = forecasts_df.index\n",
    "forecasts_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# forecasts_df.head()\n",
    "# forecasts_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_y_true_df = pd.concat(total_y_true_data)\n",
    "total_y_true_df = total_y_true_df.sort_values(by=[\"unique_id\", \"ds\"])\n",
    "\n",
    "# total_y_true_df.head()\n",
    "# total_y_true_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(total_y_true_df, forecasts_df, on=[\"ds\", \"unique_id\"], how=\"inner\")\n",
    "\n",
    "# merged_df.head()\n",
    "# merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    merged_df[f'{model}_error'] = merged_df[f'{model}'] - merged_df['y']\n",
    "    \n",
    "    # mae_model = mae(merged_df['y'], merged_df[f'{model}'])\n",
    "    # mse_model = mse(merged_df['y'], merged_df[f'{model}'])\n",
    "    \n",
    "    # print(f'{model} horizon {horizon} - MAE: {mae_model:.3f}')\n",
    "    # print(f'{model} horizon {horizon} - MSE: {mse_model:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 전체 실험 결과 출력\n",
    "\n",
    "model_name_list = ['TSMixerx', 'NHITS', 'NBEATSx', 'LSTM', 'GRU']\n",
    "realpower_df  = merged_df[merged_df[\"unique_id\"] == \"RealPower\"]\n",
    "label_df      = pd.read_csv(os.path.join(root, CFG['label3']))\n",
    "true_label    = label_df['label']\n",
    "\n",
    "anomaly_score(realpower_df, true_label, model_name_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### visualization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visual model 결정하면 됨\n",
    "\n",
    "# model_name_list = ['TSMixerx', 'NHITS', 'NBEATSx', 'LSTM', 'GRU']\n",
    "\n",
    "visual_model = 'TSMixerx'\n",
    "errors = merged_df.loc[merged_df['unique_id'] == 'RealPower', f'{visual_model}_error'] ## error 바꿔보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_  = -10.0\n",
    "max_  = 10.0\n",
    "bins_ = 100\n",
    "\n",
    "hist_counts, bin_edges = np.histogram(errors, bins=bins_, range=(min_, max_))\n",
    "\n",
    "factor = (max_ - min_) / bins_\n",
    "bins   = bins_\n",
    "\n",
    "x = []\n",
    "for i in range(bins):\n",
    "    x.append(min_ + factor * float(i))\n",
    "\n",
    "plt.bar(x, hist_counts, align='center', width=factor)\n",
    "plt.xlabel('Prediction Errors')\n",
    "plt.ylabel('Number of Error Values')\n",
    "plt.title('Histogram of Prediction Errors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 실제 값 비교 시각화\n",
    "\n",
    "realpower_df = merged_df[merged_df[\"unique_id\"] == \"RealPower\"]\n",
    "\n",
    "# Plot TSMixer, NHITS, and y over the ds (time) axis\n",
    "plt.figure(figsize=(30, 12))\n",
    "plt.plot(realpower_df[\"ds\"], realpower_df[f\"{visual_model}\"], label=f\"{visual_model}\", linestyle='-')#, marker='o')\n",
    "# plt.plot(realpower_df[\"ds\"], realpower_df[\"NHITS\"], label=\"NHITS\", linestyle='-')#, marker='x')\n",
    "plt.plot(realpower_df[\"ds\"], realpower_df[\"y\"], label=\"Actual (y)\", linestyle='-')#, marker='s')\n",
    "\n",
    "# Configure the plot\n",
    "plt.xlabel(\"Time (ds)\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.title(\"RealPower - TSMixer, NHITS, and Actual Values Over Time\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 잔차 시각화\n",
    "\n",
    "realpower_df = merged_df[merged_df[\"unique_id\"] == \"RealPower\"]\n",
    "\n",
    "# Plot TSMixer, NHITS, and y over the ds (time) axis\n",
    "plt.figure(figsize=(30, 12))\n",
    "plt.plot(realpower_df[\"ds\"], realpower_df[f\"{visual_model}_error\"], label=f\"{visual_model}_error\", linestyle='-')#, marker='o')\n",
    "# plt.plot(realpower_df[\"ds\"], realpower_df[\"NHITS_error\"], label=\"NHITS_error\", linestyle='-')#, marker='x')\n",
    "\n",
    "# Configure the plot\n",
    "plt.xlabel(\"Time (ds)\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.title(\"RealPower - TSMixer, NHITS, and Actual Values Over Time\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Z 스코어 시각화\n",
    "\n",
    "# error values\n",
    "final_scores = realpower_df[f\"{visual_model}_error\"].to_numpy()  ## error 값 수정하여 비교\n",
    "threshold    = CFG['threshold']\n",
    "\n",
    "# Calculate Z-scores\n",
    "avg     = np.mean(final_scores)\n",
    "sigma   = np.std(final_scores)\n",
    "Z_score = (final_scores - avg) / sigma\n",
    "\n",
    "# Anomaly detection using numpy (vectorized approach)\n",
    "pred_bin1 = (np.abs(Z_score) > threshold).astype(int)\n",
    "\n",
    "# Threshold lines for visualization\n",
    "pred_length = len(final_scores)\n",
    "thre        = np.full(pred_length, threshold)\n",
    "thre_minus  = np.full(pred_length, -threshold)\n",
    "\n",
    "# Plot the Z-scores with thresholds\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(Z_score, label=\"Z-score\", marker='o')\n",
    "plt.plot(thre, label=\"Threshold\", linestyle=\"--\", color=\"red\")\n",
    "plt.plot(thre_minus, label=\"-Threshold\", linestyle=\"--\", color=\"blue\")\n",
    "plt.title(\"Z-Score Anomaly Detection\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Z-Score\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df   = pd.read_csv(os.path.join(root, CFG['label3']))\n",
    "true_label = label_df['label']\n",
    "\n",
    "pred_bin = pred_bin1\n",
    "\n",
    "true = []\n",
    "true = true_label[20:20+ pred_length]\n",
    "\n",
    "pred = np.array(pred_bin)\n",
    "gt   = np.array(true)\n",
    "print(pred.shape, gt.shape, true_label.shape, pred_length)\n",
    "accuracy = accuracy_score(gt, pred)\n",
    "precision, recall, f_score, support = precision_recall_fscore_support(gt, pred,\n",
    "    average='binary')\n",
    "\n",
    "print(pred.shape, gt.shape)\n",
    "print(\n",
    "    \"Accuracy : {:0.4f}, Precision : {:0.4f}, Recall : {:0.4f}, F-score : {:0.4f}\".format(\n",
    "    accuracy, precision,\n",
    "    recall, f_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference OK1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_windowed_data, total_y_true_data = create_windowed_dataset(test_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (주의) 출력이 아주 김, 끝나면 출력 삭제\n",
    "\n",
    "\n",
    "forecasts = time_series_anomaly_detection(nf, total_windowed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_df = pd.concat(forecasts)\n",
    "forecasts_df = forecasts_df.sort_values(by=[\"unique_id\", \"ds\"])\n",
    "forecasts_df['unique_id'] = forecasts_df.index\n",
    "forecasts_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# forecasts_df.head()\n",
    "# forecasts_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_y_true_df = pd.concat(total_y_true_data)\n",
    "total_y_true_df = total_y_true_df.sort_values(by=[\"unique_id\", \"ds\"])\n",
    "\n",
    "# total_y_true_df.head()\n",
    "# total_y_true_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(total_y_true_df, forecasts_df, on=[\"ds\", \"unique_id\"], how=\"inner\")\n",
    "\n",
    "# merged_df.head()\n",
    "# merged_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    merged_df[f'{model}_error'] = merged_df[f'{model}'] - merged_df['y']\n",
    "    \n",
    "    # mae_model = mae(merged_df['y'], merged_df[f'{model}'])\n",
    "    # mse_model = mse(merged_df['y'], merged_df[f'{model}'])\n",
    "    \n",
    "    # print(f'{model} horizon {horizon} - MAE: {mae_model:.3f}')\n",
    "    # print(f'{model} horizon {horizon} - MSE: {mse_model:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## visual model 결정하면 됨\n",
    "\n",
    "# model_name_list = ['TSMixerx', 'NHITS', 'NBEATSx', 'LSTM', 'GRU']\n",
    "\n",
    "visual_model = 'TSMixerx'\n",
    "errors = merged_df.loc[merged_df['unique_id'] == 'RealPower', f'{visual_model}_error'] ## error 바꿔보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_  = -10.0\n",
    "max_  = 10.0\n",
    "bins_ = 100\n",
    "\n",
    "hist_counts, bin_edges = np.histogram(errors, bins=bins_, range=(min_, max_))\n",
    "\n",
    "factor = (max_ - min_) / bins_\n",
    "bins   = bins_\n",
    "\n",
    "x = []\n",
    "for i in range(bins):\n",
    "    x.append(min_ + factor * float(i))\n",
    "\n",
    "plt.bar(x, hist_counts, align='center', width=factor)\n",
    "plt.xlabel('Prediction Errors')\n",
    "plt.ylabel('Number of Error Values')\n",
    "plt.title('Histogram of Prediction Errors')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 실제 값 비교 시각화\n",
    "\n",
    "realpower_df = merged_df[merged_df[\"unique_id\"] == \"RealPower\"]\n",
    "\n",
    "# Plot TSMixer, NHITS, and y over the ds (time) axis\n",
    "plt.figure(figsize=(30, 12))\n",
    "plt.plot(realpower_df[\"ds\"], realpower_df[f\"{visual_model}\"], label=f\"{visual_model}\", linestyle='-')#, marker='o')\n",
    "# plt.plot(realpower_df[\"ds\"], realpower_df[\"NHITS\"], label=\"NHITS\", linestyle='-')#, marker='x')\n",
    "plt.plot(realpower_df[\"ds\"], realpower_df[\"y\"], label=\"Actual (y)\", linestyle='-')#, marker='s')\n",
    "\n",
    "# Configure the plot\n",
    "plt.xlabel(\"Time (ds)\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.title(\"RealPower - TSMixer, NHITS, and Actual Values Over Time\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 잔차 시각화\n",
    "\n",
    "realpower_df = merged_df[merged_df[\"unique_id\"] == \"RealPower\"]\n",
    "\n",
    "# Plot TSMixer, NHITS, and y over the ds (time) axis\n",
    "plt.figure(figsize=(30, 12))\n",
    "plt.plot(realpower_df[\"ds\"], realpower_df[f\"{visual_model}_error\"], label=f\"{visual_model}_error\", linestyle='-')#, marker='o')\n",
    "# plt.plot(realpower_df[\"ds\"], realpower_df[\"NHITS_error\"], label=\"NHITS_error\", linestyle='-')#, marker='x')\n",
    "\n",
    "# Configure the plot\n",
    "plt.xlabel(\"Time (ds)\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.title(\"RealPower - TSMixer, NHITS, and Actual Values Over Time\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Z 스코어 시각화\n",
    "\n",
    "# error values\n",
    "final_scores = realpower_df[f\"{visual_model}_error\"].to_numpy()  ## error 값 수정하여 비교\n",
    "threshold    = CFG['threshold']\n",
    "\n",
    "# Calculate Z-scores\n",
    "avg     = np.mean(final_scores)\n",
    "sigma   = np.std(final_scores)\n",
    "Z_score = (final_scores - avg) / sigma\n",
    "\n",
    "# Anomaly detection using numpy (vectorized approach)\n",
    "pred_bin1 = (np.abs(Z_score) > threshold).astype(int)\n",
    "\n",
    "# Threshold lines for visualization\n",
    "pred_length = len(final_scores)\n",
    "thre        = np.full(pred_length, threshold)\n",
    "thre_minus  = np.full(pred_length, -threshold)\n",
    "\n",
    "# Plot the Z-scores with thresholds\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(Z_score, label=\"Z-score\", marker='o')\n",
    "plt.plot(thre, label=\"Threshold\", linestyle=\"--\", color=\"red\")\n",
    "plt.plot(thre_minus, label=\"-Threshold\", linestyle=\"--\", color=\"blue\")\n",
    "plt.title(\"Z-Score Anomaly Detection\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Z-Score\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
